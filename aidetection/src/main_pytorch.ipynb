{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08960e9f-40ab-4667-988a-cd9eea901961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from transformers import ViTForImageClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd40c079-7dd9-4d74-b678-bd8acfad2d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查是否有可用的 GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6565522-fe30-46f4-b092-83bfd16850a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at ../input/pretrained_vit_model and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_63769/2925809810.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load('../output/vit_model.pth', map_location=device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ViTForImageClassification(\n",
       "  (vit): ViTModel(\n",
       "    (embeddings): ViTEmbeddings(\n",
       "      (patch_embeddings): ViTPatchEmbeddings(\n",
       "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): ViTEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ViTLayer(\n",
       "          (attention): ViTSdpaAttention(\n",
       "            (attention): ViTSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载预训练模型\n",
    "# model = torch.load('../output/vit_model.pth')\n",
    "# model = model.to(device)\n",
    "# model.eval()\n",
    "\n",
    "# 创建模型实例\n",
    "local_model_path = \"../input/pretrained_vit_model\"\n",
    "\n",
    "model = ViTForImageClassification.from_pretrained(local_model_path, num_labels=2)\n",
    "\n",
    "# 加载状态字典\n",
    "state_dict = torch.load('../output/vit_model.pth', map_location=device)\n",
    "\n",
    "# 将状态字典加载到模型中\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "# 将模型移动到设备（GPU或CPU）\n",
    "model.to(device)\n",
    "\n",
    "# 设置为评估模式\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dece60f-32c3-47fb-8377-0f0eb2d6ac66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import ViTForImageClassification, ViTImageProcessor\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# 加载图像处理器\n",
    "image_processor = ViTImageProcessor.from_pretrained(local_model_path)\n",
    "\n",
    "\n",
    "def predict_images(image_folder):\n",
    "    predicted_results = {}\n",
    "    for image_name in os.listdir(image_folder):\n",
    "        image_path = os.path.join(image_folder, image_name)\n",
    "        \n",
    "        # 检查文件扩展名，确保只处理图像文件\n",
    "        if not image_name.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "        except (UnidentifiedImageError, IOError):\n",
    "            print(f\"Cannot identify image file {image_path}. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # 调整图像大小为224x224\n",
    "        image = image.resize((224, 224))\n",
    "        \n",
    "        inputs = image_processor(images=image, return_tensors=\"pt\")\n",
    "        \n",
    "        # 将输入数据移动到设备\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        \n",
    "        # 使用模型进行推理\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "            predicted_class = predicted.item()\n",
    "                \n",
    "        # 互换标签\n",
    "        # if predicted_class == 0:\n",
    "        #     predicted_class = 1\n",
    "        # elif predicted_class == 1:\n",
    "        #     predicted_class = 0\n",
    "        \n",
    "        predicted_results[image_name] = predicted_class\n",
    "    return predicted_results\n",
    "\n",
    "# 指定图片文件夹\n",
    "image_folder = '../testdata'\n",
    "predicted_results = predict_images(image_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65946a13-f27a-43c8-a694-c9d4d4c61c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "# 将结果写入output.csv\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 去掉文件格式后缀并对字典的键（文件名）进行排序\n",
    "sorted_predicted_results = sorted(\n",
    "    (os.path.splitext(image_name)[0], predicted_class) for image_name, predicted_class in predicted_results.items()\n",
    ")\n",
    "\n",
    "# 将排序后的结果转换为DataFrame\n",
    "df = pd.DataFrame(sorted_predicted_results, columns=['ImageName', 'PredictedClass'])\n",
    "\n",
    "# 将结果写入output.csv\n",
    "df.to_csv('../cla_pre.csv', index=False, header=False)\n",
    "print('ok')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
